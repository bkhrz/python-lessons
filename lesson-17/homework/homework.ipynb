{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T00:35:42.359771Z",
     "start_time": "2025-03-28T00:35:42.155465Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from pandas import read_csv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T00:49:53.551110Z",
     "start_time": "2025-03-28T00:49:53.534905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with sqlite3.connect('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/chinook.db') as con:\n",
    "    df_customers = pd.read_sql('SELECT * FROM customers', con = con)\n",
    "    df_invoices = pd.read_sql('SELECT * FROM invoices', con = con)\n",
    "merge = pd.merge(df_customers, df_invoices, on = 'CustomerId')\n",
    "invoices = df_invoices['CustomerId'].value_counts().reset_index()\n",
    "print(invoices)"
   ],
   "id": "71be3f19f9777762",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerId  count\n",
      "0            2      7\n",
      "1            5      7\n",
      "2           53      7\n",
      "3            6      7\n",
      "4           29      7\n",
      "5           30      7\n",
      "6           32      7\n",
      "7           44      7\n",
      "8            9      7\n",
      "9           11      7\n",
      "10          47      7\n",
      "11          49      7\n",
      "12          26      7\n",
      "13          28      7\n",
      "14           7      7\n",
      "15          50      7\n",
      "16          43      7\n",
      "17          45      7\n",
      "18          22      7\n",
      "19          24      7\n",
      "20           1      7\n",
      "21           3      7\n",
      "22          39      7\n",
      "23          41      7\n",
      "24          18      7\n",
      "25          20      7\n",
      "26          56      7\n",
      "27          58      7\n",
      "28          51      7\n",
      "29          27      7\n",
      "30           4      7\n",
      "31          21      7\n",
      "32           8      7\n",
      "33          14      7\n",
      "34          23      7\n",
      "35          37      7\n",
      "36          38      7\n",
      "37          40      7\n",
      "38          42      7\n",
      "39          46      7\n",
      "40          52      7\n",
      "41          16      7\n",
      "42          17      7\n",
      "43          19      7\n",
      "44          25      7\n",
      "45          15      7\n",
      "46          31      7\n",
      "47          54      7\n",
      "48          55      7\n",
      "49          57      7\n",
      "50          10      7\n",
      "51          33      7\n",
      "52          34      7\n",
      "53          36      7\n",
      "54          48      7\n",
      "55          12      7\n",
      "56          13      7\n",
      "57          35      7\n",
      "58          59      6\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T00:59:43.136894Z",
     "start_time": "2025-03-28T00:59:43.084591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1_movie = pd.read_csv('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/movie.csv')[['director_name', 'color']]\n",
    "df2_movie = pd.read_csv('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/movie.csv')[['director_name', 'num_critic_for_reviews']]\n",
    "\n",
    "left_join = pd.merge(df1_movie, df2_movie, on = 'director_name', how = 'left')\n",
    "outer_join = pd.merge(df1_movie, df2_movie, on = 'director_name', how='outer')\n",
    "\n",
    "print(left_join.shape[0])\n",
    "print(outer_join.shape[0])"
   ],
   "id": "66dbacd7dc797bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30300\n",
      "30300\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:13:07.023945Z",
     "start_time": "2025-03-28T01:13:06.966910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_titanic = pd.read_excel('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/titanic.xlsx')\n",
    "avg_age = df_titanic.groupby('Pclass')['Age'].mean()\n",
    "total_fare = df_titanic.groupby('Pclass')['Fare'].sum()\n",
    "passengers = df_titanic.groupby('Pclass')['Pclass'].count()\n",
    "\n",
    "res = pd.DataFrame({\n",
    "    'Average age': avg_age,\n",
    "    'Total fare': total_fare,\n",
    "    'Count of passengers': passengers\n",
    "}).reset_index()\n",
    "\n",
    "print(res)"
   ],
   "id": "a41578af4ff25f9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Average age  Total fare  Count of passengers\n",
      "0       1    38.233441  18177.4125                  216\n",
      "1       2    29.877630   3801.8417                  184\n",
      "2       3    25.140620   6714.6951                  491\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:13:45.708208Z",
     "start_time": "2025-03-28T01:13:45.665145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_movie = pd.read_csv('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/movie.csv')\n",
    "df_movie = df_movie.groupby(['color', 'director_name'])[['num_critic_for_reviews', 'duration']].agg({\n",
    "    'num_critic_for_reviews' : 'sum',\n",
    "    'duration': 'mean'\n",
    "})\n",
    "df_movie"
   ],
   "id": "21b29c840363af7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    num_critic_for_reviews  duration\n",
       "color           director_name                                       \n",
       "Black and White Akira Kurosawa                       153.0     202.0\n",
       "                Aleksey German                       121.0     177.0\n",
       "                Alex Garland                         489.0     108.0\n",
       "                Alexander Payne                      433.0     115.0\n",
       "                Alfred Hitchcock                     434.0     119.0\n",
       "...                                                    ...       ...\n",
       "Color           Zoran Lisinac                         17.0     108.0\n",
       "                Álex de la Iglesia                    71.0     104.0\n",
       "                Émile Gaudreault                      67.0      92.0\n",
       "                Éric Tessier                           9.0      99.0\n",
       "                Étienne Faure                          9.0      98.0\n",
       "\n",
       "[2490 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Black and White</th>\n",
       "      <th>Akira Kurosawa</th>\n",
       "      <td>153.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aleksey German</th>\n",
       "      <td>121.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alex Garland</th>\n",
       "      <td>489.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Payne</th>\n",
       "      <td>433.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alfred Hitchcock</th>\n",
       "      <td>434.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Color</th>\n",
       "      <th>Zoran Lisinac</th>\n",
       "      <td>17.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Álex de la Iglesia</th>\n",
       "      <td>71.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Émile Gaudreault</th>\n",
       "      <td>67.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Éric Tessier</th>\n",
       "      <td>9.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Étienne Faure</th>\n",
       "      <td>9.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2490 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:27:15.946195Z",
     "start_time": "2025-03-28T01:27:02.643958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_flights = pd.read_parquet('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/flights')\n",
    "num_flights = df_flights.shape[0]\n",
    "avg_arr_delay = df_flights.groupby(['Year', 'Month'])[['ArrDelay', 'DepDelay']].agg({\n",
    "    'ArrDelay':'mean',\n",
    "    'DepDelay': 'max'\n",
    "})\n",
    "\n",
    "print(avg_arr_delay)"
   ],
   "id": "7b0435590d6806f5",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1942\u001B[39m, in \u001B[36mGroupBy._agg_py_fallback\u001B[39m\u001B[34m(self, how, values, ndim, alt)\u001B[39m\n\u001B[32m   1941\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1942\u001B[39m     res_values = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_grouper\u001B[49m\u001B[43m.\u001B[49m\u001B[43magg_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43mser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   1943\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/ops.py:864\u001B[39m, in \u001B[36mBaseGrouper.agg_series\u001B[39m\u001B[34m(self, obj, func, preserve_dtype)\u001B[39m\n\u001B[32m    862\u001B[39m     preserve_dtype = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m864\u001B[39m result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_aggregate_series_pure_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    866\u001B[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/ops.py:885\u001B[39m, in \u001B[36mBaseGrouper._aggregate_series_pure_python\u001B[39m\u001B[34m(self, obj, func)\u001B[39m\n\u001B[32m    884\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(splitter):\n\u001B[32m--> \u001B[39m\u001B[32m885\u001B[39m     res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    886\u001B[39m     res = extract_result(res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:2454\u001B[39m, in \u001B[36mGroupBy.mean.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m   2451\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2452\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._cython_agg_general(\n\u001B[32m   2453\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m-> \u001B[39m\u001B[32m2454\u001B[39m         alt=\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m   2455\u001B[39m         numeric_only=numeric_only,\n\u001B[32m   2456\u001B[39m     )\n\u001B[32m   2457\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result.__finalize__(\u001B[38;5;28mself\u001B[39m.obj, method=\u001B[33m\"\u001B[39m\u001B[33mgroupby\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/series.py:6549\u001B[39m, in \u001B[36mSeries.mean\u001B[39m\u001B[34m(self, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m   6541\u001B[39m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m, ndim=\u001B[32m1\u001B[39m))\n\u001B[32m   6542\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmean\u001B[39m(\n\u001B[32m   6543\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   6547\u001B[39m     **kwargs,\n\u001B[32m   6548\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m6549\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNDFrame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12420\u001B[39m, in \u001B[36mNDFrame.mean\u001B[39m\u001B[34m(self, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m  12413\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmean\u001B[39m(\n\u001B[32m  12414\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m  12415\u001B[39m     axis: Axis | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[32m0\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m  12418\u001B[39m     **kwargs,\n\u001B[32m  12419\u001B[39m ) -> Series | \u001B[38;5;28mfloat\u001B[39m:\n\u001B[32m> \u001B[39m\u001B[32m12420\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stat_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m  12421\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnanops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnanmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m  12422\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12377\u001B[39m, in \u001B[36mNDFrame._stat_function\u001B[39m\u001B[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m  12375\u001B[39m validate_bool_kwarg(skipna, \u001B[33m\"\u001B[39m\u001B[33mskipna\u001B[39m\u001B[33m\"\u001B[39m, none_allowed=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m> \u001B[39m\u001B[32m12377\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m  12378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumeric_only\u001B[49m\n\u001B[32m  12379\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/series.py:6457\u001B[39m, in \u001B[36mSeries._reduce\u001B[39m\u001B[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[39m\n\u001B[32m   6453\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m   6454\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   6455\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mwith non-numeric dtypes.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   6456\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m6457\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelegate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001B[39m, in \u001B[36mbottleneck_switch.__call__.<locals>.f\u001B[39m\u001B[34m(values, axis, skipna, **kwds)\u001B[39m\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     result = \u001B[43malt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001B[39m, in \u001B[36m_datetimelike_compat.<locals>.new_func\u001B[39m\u001B[34m(values, axis, skipna, mask, **kwargs)\u001B[39m\n\u001B[32m    402\u001B[39m     mask = isna(values)\n\u001B[32m--> \u001B[39m\u001B[32m404\u001B[39m result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:719\u001B[39m, in \u001B[36mnanmean\u001B[39m\u001B[34m(values, axis, skipna, mask)\u001B[39m\n\u001B[32m    718\u001B[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001B[32m--> \u001B[39m\u001B[32m719\u001B[39m the_sum = \u001B[43mvalues\u001B[49m\u001B[43m.\u001B[49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype_sum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    720\u001B[39m the_sum = _ensure_numeric(the_sum)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:52\u001B[39m, in \u001B[36m_sum\u001B[39m\u001B[34m(a, axis, dtype, out, keepdims, initial, where)\u001B[39m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_sum\u001B[39m(a, axis=\u001B[38;5;28;01mNone\u001B[39;00m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m, out=\u001B[38;5;28;01mNone\u001B[39;00m, keepdims=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     51\u001B[39m          initial=_NoValue, where=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: can only concatenate str (not \"int\") to str",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m flights_df = pd.read_parquet(\u001B[33m\"\u001B[39m\u001B[33m/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/flights\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Perform nested grouping and aggregation\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m flights_grouped = \u001B[43mflights_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mYear\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mMonth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mArrDelay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mDepDelay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m      8\u001B[39m \u001B[43m}\u001B[49m\u001B[43m)\u001B[49m.rename(columns={\u001B[33m\"\u001B[39m\u001B[33mFlightNum\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mTotalFlights\u001B[39m\u001B[33m\"\u001B[39m})\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# Display results\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(flights_grouped)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/generic.py:1432\u001B[39m, in \u001B[36mDataFrameGroupBy.aggregate\u001B[39m\u001B[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[39m\n\u001B[32m   1429\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m] = engine_kwargs\n\u001B[32m   1431\u001B[39m op = GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args=args, kwargs=kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1432\u001B[39m result = \u001B[43mop\u001B[49m\u001B[43m.\u001B[49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1433\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1434\u001B[39m     \u001B[38;5;66;03m# GH #52849\u001B[39;00m\n\u001B[32m   1435\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.as_index \u001B[38;5;129;01mand\u001B[39;00m is_list_like(func):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/apply.py:190\u001B[39m, in \u001B[36mApply.agg\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_str()\n\u001B[32m    189\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_dict_like(func):\n\u001B[32m--> \u001B[39m\u001B[32m190\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43magg_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(func):\n\u001B[32m    192\u001B[39m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[32m    193\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.agg_list_like()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/apply.py:423\u001B[39m, in \u001B[36mApply.agg_dict_like\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34magg_dict_like\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> DataFrame | Series:\n\u001B[32m    416\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    417\u001B[39m \u001B[33;03m    Compute aggregation in the case of a dict-like argument.\u001B[39;00m\n\u001B[32m    418\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    421\u001B[39m \u001B[33;03m    Result of aggregation.\u001B[39;00m\n\u001B[32m    422\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43magg_or_apply_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43magg\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1608\u001B[39m, in \u001B[36mGroupByApply.agg_or_apply_dict_like\u001B[39m\u001B[34m(self, op_name)\u001B[39m\n\u001B[32m   1603\u001B[39m     kwargs.update({\u001B[33m\"\u001B[39m\u001B[33mengine\u001B[39m\u001B[33m\"\u001B[39m: engine, \u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m: engine_kwargs})\n\u001B[32m   1605\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m com.temp_setattr(\n\u001B[32m   1606\u001B[39m     obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, condition=\u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1607\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1608\u001B[39m     result_index, result_data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_dict_like\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1609\u001B[39m \u001B[43m        \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1610\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1611\u001B[39m result = \u001B[38;5;28mself\u001B[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001B[32m   1612\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/apply.py:497\u001B[39m, in \u001B[36mApply.compute_dict_like\u001B[39m\u001B[34m(self, op_name, selected_obj, selection, kwargs)\u001B[39m\n\u001B[32m    493\u001B[39m         results += key_data\n\u001B[32m    494\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    495\u001B[39m     \u001B[38;5;66;03m# key used for column selection and output\u001B[39;00m\n\u001B[32m    496\u001B[39m     results = [\n\u001B[32m--> \u001B[39m\u001B[32m497\u001B[39m         \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gotitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    498\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m key, how \u001B[38;5;129;01min\u001B[39;00m func.items()\n\u001B[32m    499\u001B[39m     ]\n\u001B[32m    500\u001B[39m     keys = \u001B[38;5;28mlist\u001B[39m(func.keys())\n\u001B[32m    502\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m keys, results\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/generic.py:249\u001B[39m, in \u001B[36mSeriesGroupBy.aggregate\u001B[39m\u001B[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[39m\n\u001B[32m    247\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m engine_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    248\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m] = engine_kwargs\n\u001B[32m--> \u001B[39m\u001B[32m249\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func, abc.Iterable):\n\u001B[32m    252\u001B[39m     \u001B[38;5;66;03m# Catch instances of lists / tuples\u001B[39;00m\n\u001B[32m    253\u001B[39m     \u001B[38;5;66;03m# but not the class list / tuple itself.\u001B[39;00m\n\u001B[32m    254\u001B[39m     func = maybe_mangle_lambdas(func)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:2452\u001B[39m, in \u001B[36mGroupBy.mean\u001B[39m\u001B[34m(self, numeric_only, engine, engine_kwargs)\u001B[39m\n\u001B[32m   2445\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._numba_agg_general(\n\u001B[32m   2446\u001B[39m         grouped_mean,\n\u001B[32m   2447\u001B[39m         executor.float_dtype_mapping,\n\u001B[32m   2448\u001B[39m         engine_kwargs,\n\u001B[32m   2449\u001B[39m         min_periods=\u001B[32m0\u001B[39m,\n\u001B[32m   2450\u001B[39m     )\n\u001B[32m   2451\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2452\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cython_agg_general\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2453\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   2454\u001B[39m \u001B[43m        \u001B[49m\u001B[43malt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2455\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2456\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2457\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result.__finalize__(\u001B[38;5;28mself\u001B[39m.obj, method=\u001B[33m\"\u001B[39m\u001B[33mgroupby\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1998\u001B[39m, in \u001B[36mGroupBy._cython_agg_general\u001B[39m\u001B[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001B[39m\n\u001B[32m   1995\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001B[32m   1996\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[32m-> \u001B[39m\u001B[32m1998\u001B[39m new_mgr = \u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgrouped_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1999\u001B[39m res = \u001B[38;5;28mself\u001B[39m._wrap_agged_manager(new_mgr)\n\u001B[32m   2000\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m how \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33midxmin\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33midxmax\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/internals/base.py:367\u001B[39m, in \u001B[36mSingleDataManager.grouped_reduce\u001B[39m\u001B[34m(self, func)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgrouped_reduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func):\n\u001B[32m    366\u001B[39m     arr = \u001B[38;5;28mself\u001B[39m.array\n\u001B[32m--> \u001B[39m\u001B[32m367\u001B[39m     res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    368\u001B[39m     index = default_index(\u001B[38;5;28mlen\u001B[39m(res))\n\u001B[32m    370\u001B[39m     mgr = \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).from_array(res, index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1995\u001B[39m, in \u001B[36mGroupBy._cython_agg_general.<locals>.array_func\u001B[39m\u001B[34m(values)\u001B[39m\n\u001B[32m   1992\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[32m   1994\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m alt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1995\u001B[39m result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_agg_py_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malt\u001B[49m\u001B[43m=\u001B[49m\u001B[43malt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1996\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/pyCourse/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1946\u001B[39m, in \u001B[36mGroupBy._agg_py_fallback\u001B[39m\u001B[34m(self, how, values, ndim, alt)\u001B[39m\n\u001B[32m   1944\u001B[39m     msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33magg function failed [how->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhow\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m,dtype->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mser.dtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1945\u001B[39m     \u001B[38;5;66;03m# preserve the kind of exception that raised\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1946\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(err)(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   1948\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ser.dtype == \u001B[38;5;28mobject\u001B[39m:\n\u001B[32m   1949\u001B[39m     res_values = res_values.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[31mTypeError\u001B[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:34:52.399691Z",
     "start_time": "2025-03-28T01:34:52.332577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_titanic = pd.read_excel('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/titanic.xlsx')\n",
    "def categorize(x):\n",
    "    if x>18:\n",
    "        return 'Adult'\n",
    "    return 'Child'\n",
    "new_clm = df_titanic['Age'].apply(categorize)\n",
    "df_titanic['Age group'] = new_clm\n",
    "print(df_titanic)"
   ],
   "id": "c80ec8d4969ffc7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked Age group  \n",
      "0        0         A/5 21171   7.2500   NaN        S     Adult  \n",
      "1        0          PC 17599  71.2833   C85        C     Adult  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S     Adult  \n",
      "3        0            113803  53.1000  C123        S     Adult  \n",
      "4        0            373450   8.0500   NaN        S     Adult  \n",
      "..     ...               ...      ...   ...      ...       ...  \n",
      "886      0            211536  13.0000   NaN        S     Adult  \n",
      "887      0            112053  30.0000   B42        S     Adult  \n",
      "888      2        W./C. 6607  23.4500   NaN        S     Child  \n",
      "889      0            111369  30.0000  C148        C     Adult  \n",
      "890      0            370376   7.7500   NaN        Q     Adult  \n",
      "\n",
      "[891 rows x 13 columns]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:35:56.186999Z",
     "start_time": "2025-03-28T01:35:56.153369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_employee = pd.read_csv('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/employee.csv')\n",
    "df_employee['Normalized Salary'] = df_employee.groupby('DEPARTMENT')['BASE_SALARY'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "print(df_employee)"
   ],
   "id": "7872fead0a85a851",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UNIQUE_ID               POSITION_TITLE                     DEPARTMENT  \\\n",
      "0             0  ASSISTANT DIRECTOR (EX LVL)    Municipal Courts Department   \n",
      "1             1            LIBRARY ASSISTANT                        Library   \n",
      "2             2               POLICE OFFICER  Houston Police Department-HPD   \n",
      "3             3            ENGINEER/OPERATOR  Houston Fire Department (HFD)   \n",
      "4             4                  ELECTRICIAN    General Services Department   \n",
      "...         ...                          ...                            ...   \n",
      "1995       1995               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1996       1996       COMMUNICATIONS CAPTAIN  Houston Fire Department (HFD)   \n",
      "1997       1997               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1998       1998               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1999       1999                 FIRE FIGHTER  Houston Fire Department (HFD)   \n",
      "\n",
      "      BASE_SALARY                       RACE EMPLOYMENT_TYPE  GENDER  \\\n",
      "0        121862.0            Hispanic/Latino       Full Time  Female   \n",
      "1         26125.0            Hispanic/Latino       Full Time  Female   \n",
      "2         45279.0                      White       Full Time    Male   \n",
      "3         63166.0                      White       Full Time    Male   \n",
      "4         56347.0                      White       Full Time    Male   \n",
      "...           ...                        ...             ...     ...   \n",
      "1995      43443.0                      White       Full Time    Male   \n",
      "1996      66523.0  Black or African American       Full Time    Male   \n",
      "1997      43443.0                      White       Full Time    Male   \n",
      "1998      55461.0     Asian/Pacific Islander       Full Time    Male   \n",
      "1999      51194.0            Hispanic/Latino       Full Time    Male   \n",
      "\n",
      "     EMPLOYMENT_STATUS   HIRE_DATE    JOB_DATE  Normalized Salary  \n",
      "0               Active  2006-06-12  2012-10-13           1.000000  \n",
      "1               Active  2000-07-19  2010-09-18           0.000000  \n",
      "2               Active  2015-02-03  2015-02-03           0.116351  \n",
      "3               Active  1982-02-08  1991-05-25           0.192491  \n",
      "4               Active  1989-06-19  1994-10-22           0.479189  \n",
      "...                ...         ...         ...                ...  \n",
      "1995            Active  2014-06-09  2015-06-09           0.105837  \n",
      "1996            Active  2003-09-02  2013-10-06           0.210879  \n",
      "1997            Active  2014-10-13  2015-10-13           0.105837  \n",
      "1998            Active  2009-01-20  2011-07-02           0.174655  \n",
      "1999            Active  2009-01-12  2010-07-12           0.126914  \n",
      "\n",
      "[2000 rows x 11 columns]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:38:14.553283Z",
     "start_time": "2025-03-28T01:38:14.515686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_duration(x):\n",
    "    if x<60:\n",
    "        return 'short'\n",
    "    elif x>=60 and x<=120:\n",
    "        return 'medium'\n",
    "    return 'long'\n",
    "\n",
    "df_movie = pd.read_csv('/Users/behruz/PycharmProjects/pyCourse/lesson-17/data/movie.csv')\n",
    "df_movie['duration_category'] = df_movie['duration'].apply(categorize_duration)\n",
    "print(df_movie)"
   ],
   "id": "2fca29b3f17702b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color      director_name  num_critic_for_reviews  duration  \\\n",
      "0     Color      James Cameron                   723.0     178.0   \n",
      "1     Color     Gore Verbinski                   302.0     169.0   \n",
      "2     Color         Sam Mendes                   602.0     148.0   \n",
      "3     Color  Christopher Nolan                   813.0     164.0   \n",
      "4       NaN        Doug Walker                     NaN       NaN   \n",
      "...     ...                ...                     ...       ...   \n",
      "4911  Color        Scott Smith                     1.0      87.0   \n",
      "4912  Color                NaN                    43.0      43.0   \n",
      "4913  Color   Benjamin Roberds                    13.0      76.0   \n",
      "4914  Color        Daniel Hsia                    14.0     100.0   \n",
      "4915  Color           Jon Gunn                    43.0      90.0   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                         0.0                   855.0  Joel David Moore   \n",
      "1                       563.0                  1000.0     Orlando Bloom   \n",
      "2                         0.0                   161.0      Rory Kinnear   \n",
      "3                     22000.0                 23000.0    Christian Bale   \n",
      "4                       131.0                     NaN        Rob Walker   \n",
      "...                       ...                     ...               ...   \n",
      "4911                      2.0                   318.0     Daphne Zuniga   \n",
      "4912                      NaN                   319.0     Valorie Curry   \n",
      "4913                      0.0                     0.0     Maxwell Moody   \n",
      "4914                      0.0                   489.0     Daniel Henney   \n",
      "4915                     16.0                    16.0  Brian Herzlinger   \n",
      "\n",
      "      actor_1_facebook_likes        gross                           genres  \\\n",
      "0                     1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
      "1                    40000.0  309404152.0         Action|Adventure|Fantasy   \n",
      "2                    11000.0  200074175.0        Action|Adventure|Thriller   \n",
      "3                    27000.0  448130642.0                  Action|Thriller   \n",
      "4                      131.0          NaN                      Documentary   \n",
      "...                      ...          ...                              ...   \n",
      "4911                   637.0          NaN                     Comedy|Drama   \n",
      "4912                   841.0          NaN     Crime|Drama|Mystery|Thriller   \n",
      "4913                     0.0          NaN            Drama|Horror|Thriller   \n",
      "4914                   946.0      10443.0             Comedy|Drama|Romance   \n",
      "4915                    86.0      85222.0                      Documentary   \n",
      "\n",
      "      ... language country  content_rating       budget title_year  \\\n",
      "0     ...  English     USA           PG-13  237000000.0     2009.0   \n",
      "1     ...  English     USA           PG-13  300000000.0     2007.0   \n",
      "2     ...  English      UK           PG-13  245000000.0     2015.0   \n",
      "3     ...  English     USA           PG-13  250000000.0     2012.0   \n",
      "4     ...      NaN     NaN             NaN          NaN        NaN   \n",
      "...   ...      ...     ...             ...          ...        ...   \n",
      "4911  ...  English  Canada             NaN          NaN     2013.0   \n",
      "4912  ...  English     USA           TV-14          NaN        NaN   \n",
      "4913  ...  English     USA             NaN       1400.0     2013.0   \n",
      "4914  ...  English     USA           PG-13          NaN     2012.0   \n",
      "4915  ...  English     USA              PG       1100.0     2004.0   \n",
      "\n",
      "      actor_2_facebook_likes imdb_score aspect_ratio  movie_facebook_likes  \\\n",
      "0                      936.0        7.9         1.78                 33000   \n",
      "1                     5000.0        7.1         2.35                     0   \n",
      "2                      393.0        6.8         2.35                 85000   \n",
      "3                    23000.0        8.5         2.35                164000   \n",
      "4                       12.0        7.1          NaN                     0   \n",
      "...                      ...        ...          ...                   ...   \n",
      "4911                   470.0        7.7          NaN                    84   \n",
      "4912                   593.0        7.5        16.00                 32000   \n",
      "4913                     0.0        6.3          NaN                    16   \n",
      "4914                   719.0        6.3         2.35                   660   \n",
      "4915                    23.0        6.6         1.85                   456   \n",
      "\n",
      "     duration_category  \n",
      "0                 long  \n",
      "1                 long  \n",
      "2                 long  \n",
      "3                 long  \n",
      "4                 long  \n",
      "...                ...  \n",
      "4911            medium  \n",
      "4912             short  \n",
      "4913            medium  \n",
      "4914            medium  \n",
      "4915            medium  \n",
      "\n",
      "[4916 rows x 29 columns]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:43:12.201283Z",
     "start_time": "2025-03-28T01:43:12.179387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_survivors(x):\n",
    "    return x[x['Survived'] == 1]\n",
    "\n",
    "def fill_missing_age(x):\n",
    "    mean_age = x['Age'].mean()\n",
    "    return x.assign(Age = x['Age'].fillna(mean_age))\n",
    "\n",
    "def add_fare_per_age(x):\n",
    "    x['Fare_Per_Age'] = x['Fare']/x['Age']\n",
    "    return x\n",
    "\n",
    "df_titanic_final = (\n",
    "    df_titanic.pipe(filter_survivors)\n",
    "    .pipe(fill_missing_age)\n",
    "    .pipe(add_fare_per_age)\n",
    "    )\n",
    "\n",
    "print(df_titanic_final)"
   ],
   "id": "53529f9313f258f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "..           ...       ...     ...   \n",
      "875          876         1       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "887          888         1       1   \n",
      "889          890         1       1   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked Age group  Fare_Per_Age  \n",
      "1        0          PC 17599  71.2833   C85        C     Adult      1.875876  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S     Adult      0.304808  \n",
      "3        0            113803  53.1000  C123        S     Adult      1.517143  \n",
      "8        2            347742  11.1333   NaN        S     Adult      0.412344  \n",
      "9        0            237736  30.0708   NaN        C     Child      2.147914  \n",
      "..     ...               ...      ...   ...      ...       ...           ...  \n",
      "875      0              2667   7.2250   NaN        C     Child      0.481667  \n",
      "879      1             11767  83.1583   C50        C     Adult      1.484970  \n",
      "880      1            230433  26.0000   NaN        S     Adult      1.040000  \n",
      "887      0            112053  30.0000   B42        S     Adult      1.578947  \n",
      "889      0            111369  30.0000  C148        C     Adult      1.153846  \n",
      "\n",
      "[342 rows x 14 columns]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:50:19.519765Z",
     "start_time": "2025-03-28T01:50:05.752006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_flights[\"DepDelay\"] = pd.to_numeric(df_flights[\"DepDelay\"], errors=\"coerce\")\n",
    "df_flights[\"AirTime\"] = pd.to_numeric(df_flights[\"AirTime\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "filtered_flights = (\n",
    "    df_flights[df_flights[\"DepDelay\"] > 30]\n",
    "    .assign(Delay_Per_Hour=lambda df: df[\"DepDelay\"] / df[\"AirTime\"])\n",
    "    .dropna(subset=[\"Delay_Per_Hour\"])  # Drop rows with NaN values\n",
    ")\n",
    "\n",
    "print(filtered_flights.head())"
   ],
   "id": "e9c5d9a4eb025256",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year Quarter Month DayofMonth DayOfWeek  FlightDate Reporting_Airline  \\\n",
      "11  2022       2     4         26         2  2022-04-26                OH   \n",
      "32  2022       2     4         13         3  2022-04-13                OH   \n",
      "33  2022       2     4         14         4  2022-04-14                OH   \n",
      "37  2022       2     4         18         1  2022-04-18                OH   \n",
      "44  2022       2     4         25         1  2022-04-25                OH   \n",
      "\n",
      "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
      "11                    20397                          OH      N572NN  ...   \n",
      "32                    20397                          OH      N576NN  ...   \n",
      "33                    20397                          OH      N559NN  ...   \n",
      "37                    20397                          OH      N559NN  ...   \n",
      "44                    20397                          OH      N556NN  ...   \n",
      "\n",
      "   Div4TailNum Div5Airport Div5AirportID Div5AirportSeqID Div5WheelsOn  \\\n",
      "11        None        None          None             None         None   \n",
      "32        None        None          None             None         None   \n",
      "33        None        None          None             None         None   \n",
      "37        None        None          None             None         None   \n",
      "44        None        None          None             None         None   \n",
      "\n",
      "   Div5TotalGTime Div5LongestGTime Div5WheelsOff Div5TailNum Delay_Per_Hour  \n",
      "11           None             None          None        None       0.507463  \n",
      "32           None             None          None        None       1.333333  \n",
      "33           None             None          None        None       0.944444  \n",
      "37           None             None          None        None       1.696970  \n",
      "44           None             None          None        None       1.914286  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
